{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79e6ddd-10b8-4f40-abb3-5ee003bc7108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MP KUMAR\\AppData\\Local\\Temp\\ipykernel_22408\\967770361.py:43: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Dep_Hour'] = pd.to_datetime(df['Dep_Time']).dt.hour\n",
      "C:\\Users\\MP KUMAR\\AppData\\Local\\Temp\\ipykernel_22408\\967770361.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Dep_Minute'] = pd.to_datetime(df['Dep_Time']).dt.minute\n",
      "C:\\Users\\MP KUMAR\\AppData\\Local\\Temp\\ipykernel_22408\\967770361.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Arrival_Hour'] = pd.to_datetime(df['Arrival_Time']).dt.hour\n",
      "C:\\Users\\MP KUMAR\\AppData\\Local\\Temp\\ipykernel_22408\\967770361.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Arrival_Minute'] = pd.to_datetime(df['Arrival_Time']).dt.minute\n",
      "C:\\Users\\MP KUMAR\\AppData\\Local\\Temp\\ipykernel_22408\\967770361.py:58: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Total_Stops'] = df['Total_Stops'].replace({'non-stop': 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Saved as 'cleaned_flight_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads the dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Cleans the dataset by handling missing values and duplicates.\"\"\"\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocesses data by handling categorical variables and converting 'Duration'.\"\"\"\n",
    "    \n",
    "    # Convert 'Duration' into total minutes\n",
    "    def convert_duration(duration):\n",
    "        h, m = 0, 0\n",
    "        if 'h' in duration:\n",
    "            h = int(duration.split('h')[0])\n",
    "            duration = duration.split('h')[1]\n",
    "        if 'm' in duration:\n",
    "            m = int(duration.split('m')[0])\n",
    "        return h * 60 + m\n",
    "    \n",
    "    df['Duration'] = df['Duration'].apply(convert_duration)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Performs feature engineering and encodes categorical variables.\"\"\"\n",
    "    \n",
    "    # Convert date columns to datetime format\n",
    "    df['Date_of_Journey'] = pd.to_datetime(df['Date_of_Journey'], format='%d/%m/%Y')\n",
    "    df['Journey_Day'] = df['Date_of_Journey'].dt.day\n",
    "    df['Journey_Month'] = df['Date_of_Journey'].dt.month\n",
    "    df.drop(['Date_of_Journey'], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert Departure and Arrival Time\n",
    "    df['Dep_Hour'] = pd.to_datetime(df['Dep_Time']).dt.hour\n",
    "    df['Dep_Minute'] = pd.to_datetime(df['Dep_Time']).dt.minute\n",
    "    df.drop(['Dep_Time'], axis=1, inplace=True)\n",
    "    \n",
    "    df['Arrival_Hour'] = pd.to_datetime(df['Arrival_Time']).dt.hour\n",
    "    df['Arrival_Minute'] = pd.to_datetime(df['Arrival_Time']).dt.minute\n",
    "    df.drop(['Arrival_Time'], axis=1, inplace=True)\n",
    "    \n",
    "    # Encoding categorical features\n",
    "    label_encoder = LabelEncoder()\n",
    "    categorical_features = ['Airline', 'Source', 'Destination', 'Route', 'Additional_Info']\n",
    "    for feature in categorical_features:\n",
    "        df[feature] = label_encoder.fit_transform(df[feature])\n",
    "    \n",
    "    # Convert Total_Stops to numeric\n",
    "    df['Total_Stops'] = df['Total_Stops'].replace({'non-stop': 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4})\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"C:\\Users\\Public\\GUVI\\code\\flight price prediction\\Flight_Price.csv\"  # Update with your actual file path\n",
    "    df = load_data(file_path)\n",
    "    df = preprocess_data(df)\n",
    "    df = clean_data(df)\n",
    "    df.to_csv(\"cleaned_flight_data.csv\", index=False)\n",
    "    print(\"Data preprocessing complete. Saved as 'cleaned_flight_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333ce930-d36f-4c28-9a7d-1922ff6e3f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10460 entries, 0 to 10459\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Airline          10460 non-null  int64  \n",
      " 1   Source           10460 non-null  int64  \n",
      " 2   Destination      10460 non-null  int64  \n",
      " 3   Route            10460 non-null  int64  \n",
      " 4   Duration         10460 non-null  object \n",
      " 5   Total_Stops      10460 non-null  float64\n",
      " 6   Additional_Info  10460 non-null  int64  \n",
      " 7   Price            10460 non-null  int64  \n",
      " 8   Journey_Day      10460 non-null  int64  \n",
      " 9   Journey_Month    10460 non-null  int64  \n",
      " 10  Dep_Hour         10460 non-null  int64  \n",
      " 11  Dep_Minute       10460 non-null  int64  \n",
      " 12  Arrival_Hour     10460 non-null  int64  \n",
      " 13  Arrival_Minute   10460 non-null  int64  \n",
      "dtypes: float64(1), int64(12), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "           Airline        Source   Destination         Route   Total_Stops  \\\n",
      "count  10460.00000  10460.000000  10460.000000  10460.000000  10460.000000   \n",
      "mean       3.98088      1.954015      1.438815     74.297228      0.802486   \n",
      "std        2.36380      1.186133      1.480337     36.702744      0.660579   \n",
      "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        3.00000      2.000000      0.000000     48.000000      0.000000   \n",
      "50%        4.00000      2.000000      1.000000     73.000000      1.000000   \n",
      "75%        4.00000      3.000000      2.000000    104.000000      1.000000   \n",
      "max       11.00000      4.000000      5.000000    127.000000      4.000000   \n",
      "\n",
      "       Additional_Info         Price   Journey_Day  Journey_Month  \\\n",
      "count     10460.000000  10460.000000  10460.000000   10460.000000   \n",
      "mean          7.396367   9027.360421     13.463193       4.701816   \n",
      "std           1.212117   4625.057376      8.467058       1.163676   \n",
      "min           0.000000   1759.000000      1.000000       3.000000   \n",
      "25%           8.000000   5224.000000      6.000000       3.000000   \n",
      "50%           8.000000   8266.000000     12.000000       5.000000   \n",
      "75%           8.000000  12346.250000     21.000000       6.000000   \n",
      "max           9.000000  79512.000000     27.000000       6.000000   \n",
      "\n",
      "           Dep_Hour    Dep_Minute  Arrival_Hour  Arrival_Minute  \n",
      "count  10460.000000  10460.000000  10460.000000    10460.000000  \n",
      "mean      12.476673     24.406310     13.390057       24.723231  \n",
      "std        5.726244     18.816989      6.854048       16.570287  \n",
      "min        0.000000      0.000000      0.000000        0.000000  \n",
      "25%        8.000000      5.000000      8.000000       10.000000  \n",
      "50%       11.000000     25.000000     14.000000       25.000000  \n",
      "75%       18.000000     40.000000     19.000000       35.000000  \n",
      "max       23.000000     55.000000     23.000000       55.000000  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2h 50m'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPublic\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGUVI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mflight price prediction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_flight_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update with your actual file path\u001b[39;00m\n\u001b[0;32m     49\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data(file_path)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mperform_eda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExploratory Data Analysis complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mperform_eda\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Correlation heatmap\u001b[39;00m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 20\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m\"\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Correlation Heatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2h 50m'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads the cleaned dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def perform_eda(df):\n",
    "    \"\"\"Performs exploratory data analysis (EDA) and visualizations.\"\"\"\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Distribution of Flight Prices\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df['Price'], bins=30, kde=True)\n",
    "    plt.title(\"Flight Price Distribution\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Boxplot of prices by airline\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.boxplot(x=df['Airline'], y=df['Price'])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Flight Prices by Airline\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Count of flights by total stops\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.countplot(x=df['Total_Stops'])\n",
    "    plt.title(\"Count of Flights by Number of Stops\")\n",
    "    plt.xlabel(\"Total Stops\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"C:\\Users\\Public\\GUVI\\code\\flight price prediction\\cleaned_flight_data.csv\"  # Update with your actual file path\n",
    "    df = load_data(file_path)\n",
    "    perform_eda(df)\n",
    "    print(\"Exploratory Data Analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cabac2-af6b-4fd9-b653-4c8a5834908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
